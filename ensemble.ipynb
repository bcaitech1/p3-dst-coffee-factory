{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import re\n",
    "import copy\n",
    "from re import findall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = json.load(open('/opt/ml/ensemble/outputs_/sub_star1621500901.3.csv'))\n",
    "b = json.load(open('/opt/ml/ensemble/outputs_/predictions_0.7101.csv'))\n",
    "c = json.load(open('/opt/ml/ensemble/outputs_/prediction_sumbt_06295.csv'))\n",
    "d = json.load(open('/opt/ml/ensemble/outputs_/output_tradebest_7383.csv'))\n",
    "e = json.load(open('/opt/ml/ensemble/outputs_/output_trade_07345_.csv'))\n",
    "f = json.load(open('/opt/ml/ensemble/outputs_/prediction_sumbt_06295.csv'))\n",
    "g = json.load(open('/opt/ml/ensemble/outputs_/output_tradepseudo_7679.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in [b, d, e, g]: # include open-vocab models only\n",
    "    for idx, state in result.items():\n",
    "        for i, sv in enumerate(state):\n",
    "            s, v = sv.rsplit('-', 1)\n",
    "            if \"(\" in v and v.count('(') == 1 and v[-1] == \")\":\n",
    "                l, r = v.split('(')\n",
    "                l = l.rstrip()\n",
    "                v = f\"{l} ({r}\"\n",
    "            elif \"(\" in v and v.count('(') == 1:\n",
    "                l, r = v.split('(')\n",
    "                l = l.rstrip()\n",
    "                v = f\"{l}({r}\"\n",
    "            v = v.replace(\" = \", \"=\").replace(\" & \", \"&\")\n",
    "            v = v.replace(\" =\", '=').replace(\" &\", \"&\")\n",
    "            v = v.replace(\"= \", \"=\").replace(\"& \", \"&\")\n",
    "            state[i] = f\"{s}-{v}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_state(pred_slot):\n",
    "    states = []\n",
    "    for s, v in zip(slot_meta, pred_slot):\n",
    "        if v != 'none':\n",
    "            states.append(f'{s}-{v}')\n",
    "    return states\n",
    "\n",
    "def make_every_slot(datas, weights):\n",
    "    acc = []\n",
    "    for slot in slot_meta:\n",
    "        slot_cnt = defaultdict(float)\n",
    "        for data, weight in zip(datas, weights):\n",
    "            d = {'-'.join(v.split('-')[:2]):v.split('-')[2] for v in data}\n",
    "            slot_cnt[d.get(slot, 'none')] += weight\n",
    "        maxval = max(slot_cnt.values())\n",
    "        res = [k for k, v in slot_cnt.items() if v == maxval]\n",
    "        acc.append(res[0])\n",
    "    \n",
    "    return recover_state(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cls_token(sent_A):\n",
    "    model.eval()\n",
    "    tokenized_sent = tokenizer(\n",
    "            sent_A,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512\n",
    "    )\n",
    "    with torch.no_grad():# 그라디엔트 계산 비활성화\n",
    "        outputs = model(    # **tokenized_sent\n",
    "            input_ids=tokenized_sent['input_ids'],\n",
    "            attention_mask=tokenized_sent['attention_mask'],\n",
    "            token_type_ids=tokenized_sent['token_type_ids']\n",
    "            )\n",
    "    logits = outputs[1].detach().cpu().numpy()\n",
    "    return logits\n",
    "\n",
    "slot_meta = json.load(open(\"/opt/ml/input/data/train/slot_meta.json\"))\n",
    "ontology = json.load(open(\"/opt/ml/input/data/train/ontology.json\"))\n",
    "\n",
    "\n",
    "MODEL_NAME = \"kykim/bert-kor-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "ontology_list = []\n",
    "for key in ontology:\n",
    "    if \"이름\" in key or \"출발지\" in key or \"도착지\" in key:\n",
    "        ontology_list.extend(ontology[key])\n",
    "    \n",
    "dataset_cls_hidden = []\n",
    "for q in ontology_list:\n",
    "    q_cls = get_cls_token(q)\n",
    "    dataset_cls_hidden.append(q_cls)\n",
    "dataset_cls_hidden = np.array(dataset_cls_hidden).squeeze(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicts = {}\n",
    "for i, dlg in enumerate(zip(a, b, c, d, e, f, g)):\n",
    "    predicts[dlg[0]] = make_every_slot(\n",
    "        [a[dlg[0]], b[dlg[1]], c[dlg[2]], d[dlg[3]], e[dlg[4]], f[dlg[5]], g[dlg[6]]], \n",
    "        [0.6344, 0.7101, 0.6295, 0.7383, 0.7345, 0.6295, 0.7679]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, predict in enumerate(predicts):\n",
    "    print(f'\\r{i/len(predicts)}', end='')\n",
    "    data = predicts[predict]\n",
    "    for v in data:\n",
    "        sl = v.split('-')[:2]\n",
    "        if \"이름\" in sl or \"출발지\" in sl or \"도착지\" in sl:\n",
    "            val = v.split('-')[2]\n",
    "            query_cls_hidden = get_cls_token(val)\n",
    "            cos_sim = cosine_similarity(query_cls_hidden, dataset_cls_hidden)\n",
    "            top_question = np.argmax(cos_sim)\n",
    "            if ontology_list[top_question] != val and max(cos_sim[0]) >= 0.98:\n",
    "                v = v.replace(v.split('-')[2], ontology_list[top_question]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json.dump(predicts, open('/opt/ml/ensemble/predictions002_cos.csv', 'w'), indent=2, ensure_ascii=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
