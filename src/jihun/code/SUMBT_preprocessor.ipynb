{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "U6zJMPwv3Th0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from data_utils import get_examples_from_dialogues, convert_state_dict, load_dataset\n",
    "from data_utils import OntologyDSTFeature, DSTPreprocessor, _truncate_seq_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRcGJ-tS3Th6"
   },
   "source": [
    "## Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EdwC-9ju3Th7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_file = \"/opt/ml/input/data/train_dataset/train_dials.json\"\n",
    "slot_meta = json.load(open(\"/opt/ml/input/data/train_dataset/slot_meta.json\"))\n",
    "ontology = json.load(open(\"/opt/ml/input/data/train_dataset/ontology.json\"))\n",
    "train_data, dev_data, dev_labels = load_dataset(train_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BGYx3Yts3Th7",
    "outputId": "00ef5d08-fa6a-4aa0-fc9b-ea9d17070800",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6301/6301 [00:00<00:00, 7609.35it/s]\n",
      "100%|██████████| 699/699 [00:00<00:00, 15606.57it/s]\n"
     ]
    }
   ],
   "source": [
    "train_examples = get_examples_from_dialogues(data=train_data,\n",
    "                                             user_first=True,\n",
    "                                             dialogue_level=True)\n",
    "\n",
    "dev_examples = get_examples_from_dialogues(data=dev_data,\n",
    "                                           user_first=True,\n",
    "                                           dialogue_level=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Bz1ObJdz3Th8",
    "outputId": "dfaed5ee-2b98-4e06-970c-1bc48b542301",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6301"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: pip3: not found\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install ipywidgets --user\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "aPNMRRRA3Th8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_turn = max([len(e['dialogue']) for e in train_data])\n",
    "tokenizer = BertTokenizer.from_pretrained('dsksd/bert-ko-small-minimal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_2-j1Kr3Th9"
   },
   "source": [
    "## TODO-1: SUMBT Preprocessor 정의 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keupfN2b3Th9"
   },
   "source": [
    "Ontology-based DST model인 SUMBT의 InputFeature를 만들기 위한 Preprocessor를 정의해야 합니다. <br>\n",
    "\n",
    "1. `_convert_examples_to_features` 함수의 빈칸을 매워 완성하세요.\n",
    "2. `recover_state` 함수의 빈칸을 매워 완성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CsERmb2U3Th9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SUMBTPreprocessor(DSTPreprocessor):\n",
    "    def __init__(\n",
    "        self,\n",
    "        slot_meta,\n",
    "        src_tokenizer,\n",
    "        trg_tokenizer=None,\n",
    "        ontology=None,\n",
    "        max_seq_length=64,\n",
    "        max_turn_length=14,\n",
    "    ):\n",
    "        self.slot_meta = slot_meta\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.trg_tokenizer = trg_tokenizer if trg_tokenizer else src_tokenizer\n",
    "        self.ontology = ontology\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.max_turn_length = max_turn_length\n",
    "\n",
    "    def _convert_example_to_feature(self, example):\n",
    "        guid = example[0].guid.rsplit(\"-\", 1)[0]  # dialogue_idx\n",
    "        turns = []\n",
    "        token_types = []\n",
    "        labels = []\n",
    "        num_turn = None\n",
    "        for turn in example[: self.max_turn_length]:\n",
    "            assert len(turn.current_turn) == 2\n",
    "            uttrs = []\n",
    "            for segment_idx, uttr in enumerate(turn.current_turn):\n",
    "                token = self.src_tokenizer.encode(uttr, add_special_tokens=False)\n",
    "                uttrs.append(token)\n",
    "\n",
    "            _truncate_seq_pair(uttrs[0], uttrs[1], self.max_seq_length - 3)\n",
    "            tokens = (\n",
    "                [self.src_tokenizer.cls_token_id]\n",
    "                + uttrs[0]\n",
    "                + [self.src_tokenizer.sep_token_id]\n",
    "                + uttrs[1]\n",
    "                + [self.src_tokenizer.sep_token_id]\n",
    "            )\n",
    "            token_type = [0] * (len(uttrs[0]) + 2) + [1] * (len(uttrs[1]) + 1)\n",
    "            if len(tokens) < self.max_seq_length:\n",
    "                gap = self.max_seq_length - len(tokens)\n",
    "                tokens.extend([self.src_tokenizer.pad_token_id] * gap)\n",
    "                token_type.extend([0] * gap)\n",
    "            turns.append(tokens)\n",
    "            token_types.append(token_type)\n",
    "            label = []\n",
    "            if turn.label:\n",
    "                slot_dict = convert_state_dict(turn.label)\n",
    "            else:\n",
    "                slot_dict = {}\n",
    "            for slot_type in self.slot_meta:\n",
    "                value = slot_dict.get(slot_type, \"none\")\n",
    "                # TODO\n",
    "                # raise Exception('label_idx를 ontology에서 꺼내오는 코드를 작성하세요!')\n",
    "                if value in self.ontology[slot_type]:\n",
    "                    label_idx = self.ontology[slot_type].index(value)\n",
    "                else :\n",
    "                    label_idx = self.ontology[slot_type].index(\"none\")\n",
    "                label.append(label_idx)\n",
    "            labels.append(label)\n",
    "        num_turn = len(turns)\n",
    "        if len(turns) < self.max_turn_length:\n",
    "            gap = self.max_turn_length - len(turns)\n",
    "            for _ in range(gap):\n",
    "                dummy_turn = [self.src_tokenizer.pad_token_id] * self.max_seq_length\n",
    "                turns.append(dummy_turn)\n",
    "                token_types.append(dummy_turn)\n",
    "                dummy_label = [-1] * len(self.slot_meta)\n",
    "                labels.append(dummy_label)\n",
    "        return OntologyDSTFeature(\n",
    "            guid=guid,\n",
    "            input_ids=turns,\n",
    "            segment_ids=token_types,\n",
    "            num_turn=num_turn,\n",
    "            target_ids=labels,\n",
    "        )\n",
    "\n",
    "    def convert_examples_to_features(self, examples):\n",
    "        return list(map(self._convert_example_to_feature, examples))\n",
    "\n",
    "    def recover_state(self, pred_slots, num_turn):\n",
    "        states = []\n",
    "        # TODO\n",
    "        # raise Exception('SUMBT의 아웃풋을 prediction form으로 바꾸는 코드를 작성하세요!')\n",
    "        for pred_slot in pred_slots[:num_turn]:\n",
    "            stage = []\n",
    "            for s, p in zip(self.slot_meta, pred_slot):\n",
    "                v = self.ontology[s][p]\n",
    "                if v != \"none\":\n",
    "                    state.append(f\"{s}-{v}\")\n",
    "            states.append(state)\n",
    "        return states\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        guids = [b.guid for b in batch]\n",
    "        input_ids = torch.LongTensor([b.input_ids for b in batch])\n",
    "        segment_ids = torch.LongTensor([b.segment_ids for b in batch])\n",
    "        input_masks = input_ids.ne(self.src_tokenizer.pad_token_id)\n",
    "        target_ids = torch.LongTensor([b.target_ids for b in batch])\n",
    "        num_turns = [b.num_turn for b in batch]\n",
    "        return input_ids, segment_ids, input_masks, target_ids, num_turns, guids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7dLhg9y3Th-"
   },
   "source": [
    "## Convert_Examples_to_Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "VHg0scON3Th_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "processor = SUMBTPreprocessor(slot_meta,\n",
    "                              tokenizer,\n",
    "                              ontology=ontology,  # predefined ontology\n",
    "                              max_seq_length=64,  # 각 turn마다 최대 길이\n",
    "                              max_turn_length=max_turn)  # 각 dialogue의 최대 turn 길이\n",
    "train_features = processor.convert_examples_to_features(train_examples)\n",
    "dev_features = processor.convert_examples_to_features(dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZgN9R5y03Th_",
    "outputId": "1cdb565f-1fde-4a89-d6dd-49266291d76e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6301\n",
      "699\n"
     ]
    }
   ],
   "source": [
    "print(len(train_features))  # 대화 level의 features\n",
    "print(len(dev_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SUMBT_preprocessor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
